{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hCUKZw0KSae"
      },
      "source": [
        "# Implementation: Static Pictures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CvZuAe99930"
      },
      "source": [
        "**Needed Installs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "G8nKCXo73fdI"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers pillow\n",
        "!pip install -U accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Sc5vne-Hz8"
      },
      "source": [
        "**Core Code for Person Recogntion: Model Usage + Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "v4ShSp_S4Uo6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import AutoImageProcessor, RTDetrForObjectDetection\n",
        "\n",
        "MODEL_ID = \"PekingU/rtdetr_r50vd\"\n",
        "\n",
        "# Load once (important for video later)\n",
        "processor = AutoImageProcessor.from_pretrained(MODEL_ID)\n",
        "model = RTDetrForObjectDetection.from_pretrained(MODEL_ID)\n",
        "model.eval()\n",
        "\n",
        "# Find the COCO \"person\" class id from the model config\n",
        "id2label = model.config.id2label\n",
        "PERSON_ID = [k for k, v in id2label.items() if v.lower() == \"person\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-WCVXUr89zZ"
      },
      "outputs": [],
      "source": [
        "from torchvision.ops import nms\n",
        "\n",
        "@torch.no_grad()\n",
        "def detect_people(\n",
        "    image,\n",
        "    threshold: float = 0.3,\n",
        "    min_box_area: int = 700,\n",
        "    ar_min: float = 1.05,\n",
        "    ar_max: float = 6.5,\n",
        "    nms_iou: float = 0.60,\n",
        "    device: str | torch.device = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    RT-DETR people detection with fast+strong post-processing:\n",
        "    1) model inference + threshold\n",
        "    2) keep only person\n",
        "    3) geometry filter (area + aspect ratio)\n",
        "    4) NMS dedupe\n",
        "\n",
        "    Returns:\n",
        "      dict: count, boxes, scores, labels, debug\n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    dev = torch.device(device)\n",
        "\n",
        "    model.to(dev)\n",
        "    model.eval()\n",
        "\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "\n",
        "    # --- 1) Inference ---\n",
        "    inputs = processor(images=image, return_tensors=\"pt\").to(dev)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    target_sizes = torch.tensor([image.size[::-1]], device=dev)  # (h, w)\n",
        "    det = processor.post_process_object_detection(\n",
        "        outputs, target_sizes=target_sizes, threshold=threshold\n",
        "    )[0]\n",
        "\n",
        "    debug = {\n",
        "        \"raw_total\": int(det[\"boxes\"].shape[0]),\n",
        "        \"raw_thresh\": float(threshold),\n",
        "    }\n",
        "\n",
        "    # --- 2) Person-only ---\n",
        "    person_mask = det[\"labels\"] == PERSON_ID\n",
        "    boxes = det[\"boxes\"][person_mask]\n",
        "    scores = det[\"scores\"][person_mask]\n",
        "    labels = det[\"labels\"][person_mask]\n",
        "\n",
        "    debug[\"person_after_thresh\"] = int(boxes.shape[0])\n",
        "\n",
        "    # Early exit\n",
        "    if boxes.numel() == 0:\n",
        "        return {\n",
        "            \"count\": 0,\n",
        "            \"boxes\": boxes.detach().cpu(),\n",
        "            \"scores\": scores.detach().cpu(),\n",
        "            \"labels\": labels.detach().cpu(),\n",
        "            \"debug\": debug,\n",
        "        }\n",
        "\n",
        "    # --- 3) Geometry filter ---\n",
        "    w = (boxes[:, 2] - boxes[:, 0]).clamp(min=0)\n",
        "    h = (boxes[:, 3] - boxes[:, 1]).clamp(min=0)\n",
        "    area = w * h\n",
        "    ar = h / (w + 1e-6)\n",
        "\n",
        "    # Only apply strict geometry to low-confidence detections\n",
        "    score_gate = 0.50\n",
        "    high_conf = scores >= score_gate\n",
        "\n",
        "    geom_ok = (area >= float(min_box_area)) & ((ar >= float(ar_min)) & (ar <= float(ar_max)))\n",
        "\n",
        "    # Keep all high-confidence detections, and only filter low-confidence ones\n",
        "    keep = high_conf | geom_ok\n",
        "\n",
        "    boxes = boxes[keep]\n",
        "    scores = scores[keep]\n",
        "    labels = labels[keep]\n",
        "\n",
        "    debug[\"person_after_geom\"] = int(boxes.shape[0])\n",
        "    debug[\"geom_params\"] = {\n",
        "        \"min_box_area\": min_box_area,\n",
        "        \"ar_min\": ar_min,\n",
        "        \"ar_max\": ar_max,\n",
        "        \"score_gate\": score_gate,\n",
        "        \"rule\": \"keep if high_conf OR (area>=min_area OR person-like AR)\"\n",
        "    }\n",
        "\n",
        "\n",
        "    # --- 4) NMS dedupe ---\n",
        "    keep_idx = nms(boxes, scores, float(nms_iou))\n",
        "    boxes = boxes[keep_idx]\n",
        "    scores = scores[keep_idx]\n",
        "    labels = labels[keep_idx]\n",
        "\n",
        "    debug[\"person_after_nms\"] = int(boxes.shape[0])\n",
        "    debug[\"nms_iou\"] = nms_iou\n",
        "\n",
        "    return {\n",
        "        \"count\": int(boxes.shape[0]),\n",
        "        \"boxes\": boxes.detach().cpu(),\n",
        "        \"scores\": scores.detach().cpu(),\n",
        "        \"labels\": labels.detach().cpu(),\n",
        "        \"debug\": debug,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNQtOD-V9CUY"
      },
      "outputs": [],
      "source": [
        "def count_people(image: Image.Image, **kwargs) -> int:\n",
        "    \"\"\"Convenience wrapper that returns only the count.\"\"\"\n",
        "    return detect_people(image, **kwargs)[\"count\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3hOFwqLKmL8"
      },
      "source": [
        "**Visualiztion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNtqgL1C963c"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageDraw, ImageFont\n",
        "\n",
        "def _get_default_font(size=16):\n",
        "    # Colab often lacks many fonts; fall back safely.\n",
        "    try:\n",
        "        return ImageFont.truetype(\"DejaVuSans.ttf\", size)\n",
        "    except Exception:\n",
        "        return ImageFont.load_default()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgojrzP0-NYS"
      },
      "outputs": [],
      "source": [
        "def draw_detections(\n",
        "    image,\n",
        "    boxes,\n",
        "    scores=None,\n",
        "    labels=None,\n",
        "    id2label=None,\n",
        "    max_detections=None,\n",
        "    score_format=\"{:.2f}\",\n",
        "    box_width=3,\n",
        "    font_size=16,\n",
        "):\n",
        "    \"\"\"\n",
        "    Draw bounding boxes on a PIL image.\n",
        "\n",
        "    Args:\n",
        "        image: PIL.Image\n",
        "        boxes: Tensor/array-like shape (N,4) in [x1,y1,x2,y2] pixel coords\n",
        "        scores: optional (N,)\n",
        "        labels: optional (N,)\n",
        "        id2label: optional dict mapping label_id -> name\n",
        "        max_detections: optionally draw only first K (e.g., sorted by score already)\n",
        "    Returns:\n",
        "        annotated PIL.Image\n",
        "    \"\"\"\n",
        "    img = image.copy()\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    font = _get_default_font(font_size)\n",
        "\n",
        "    if max_detections is not None:\n",
        "        boxes = boxes[:max_detections]\n",
        "        if scores is not None: scores = scores[:max_detections]\n",
        "        if labels is not None: labels = labels[:max_detections]\n",
        "\n",
        "    for i, b in enumerate(boxes):\n",
        "        x1, y1, x2, y2 = [float(v) for v in b]\n",
        "        draw.rectangle([x1, y1, x2, y2], width=box_width)\n",
        "\n",
        "        parts = []\n",
        "        if labels is not None and id2label is not None:\n",
        "            parts.append(str(id2label.get(int(labels[i]), int(labels[i]))))\n",
        "        if scores is not None:\n",
        "            parts.append(score_format.format(float(scores[i])))\n",
        "\n",
        "        if parts:\n",
        "            text = \" \".join(parts)\n",
        "            # Text background for readability\n",
        "            tx, ty = x1, max(0.0, y1 - font_size - 4)\n",
        "            tw, th = draw.textbbox((0, 0), text, font=font)[2:]\n",
        "            draw.rectangle([tx, ty, tx + tw + 6, ty + th + 4], fill=\"white\")\n",
        "            draw.text((tx + 3, ty + 2), text, font=font, fill=\"black\")\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEPEkg5_-k4w"
      },
      "outputs": [],
      "source": [
        "def visualize_people(image, detection_output, max_detections=50):\n",
        "    \"\"\"\n",
        "    Draw only the filtered 'person' detections (boxes + scores).\n",
        "    \"\"\"\n",
        "    return draw_detections(\n",
        "        image=image,\n",
        "        boxes=detection_output[\"boxes\"],\n",
        "        scores=detection_output[\"scores\"],\n",
        "        labels=detection_output[\"labels\"],\n",
        "        id2label=model.config.id2label,\n",
        "        max_detections=max_detections,\n",
        "        box_width=3,\n",
        "        font_size=16,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYc3n_zvJV10"
      },
      "source": [
        "**Folder Evalutaion Function: MAE + Exact Match**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDlZmjGEJuUk"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_image_folder_metrics(\n",
        "    folder_path: str,\n",
        "    threshold: float = 0.4,\n",
        "    nms_iou: float = 0.60,\n",
        "    min_box_area: int = 700,\n",
        "    ar_min: float = 1.05,\n",
        "    ar_max: float = 6.5,\n",
        "    device=None,\n",
        "    extensions=(\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"),\n",
        "):\n",
        "    \"\"\"\n",
        "    Evaluate a folder of images with filenames: <id>_<gtcount>.<ext>\n",
        "    Returns: (mae, exact_match_rate, n_eval)\n",
        "    \"\"\"\n",
        "    folder = Path(folder_path)\n",
        "    if not folder.exists():\n",
        "        raise FileNotFoundError(f\"Folder not found: {folder_path}\")\n",
        "\n",
        "    pattern = re.compile(r\"^(?P<id>.+)_(?P<gt>\\d+)$\")\n",
        "    image_paths = sorted([p for p in folder.iterdir() if p.suffix.lower() in extensions])\n",
        "\n",
        "    gts, preds = [], []\n",
        "\n",
        "    for p in image_paths:\n",
        "        m = pattern.match(p.stem)\n",
        "        if not m:\n",
        "            continue\n",
        "        gt = int(m.group(\"gt\"))\n",
        "\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        pred = count_people(\n",
        "            img,\n",
        "            threshold=threshold,\n",
        "            nms_iou=nms_iou,\n",
        "            min_box_area=min_box_area,\n",
        "            ar_min=ar_min,\n",
        "            ar_max=ar_max,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        gts.append(gt)\n",
        "        preds.append(int(pred))\n",
        "\n",
        "    if len(gts) == 0:\n",
        "        raise ValueError(f\"No valid images found in {folder_path} with '<id>_<gt>' naming.\")\n",
        "\n",
        "    gts = np.array(gts, dtype=float)\n",
        "    preds = np.array(preds, dtype=float)\n",
        "\n",
        "    abs_err = np.abs(preds - gts)\n",
        "    mae = float(abs_err.mean())\n",
        "    exact_match = float((abs_err == 0).mean())\n",
        "    return mae, exact_match, int(len(gts))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDOXVt3HJws3"
      },
      "source": [
        "**Sweep + Plot: Threshhold**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSKGFG_QOV8f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sweep_and_plot_threshold(\n",
        "    folder_path: str,\n",
        "    thresholds=(0.2, 0.3, 0.4, 0.5, 0.6),\n",
        "    fixed_nms_iou=0.60,\n",
        "    fixed_min_box_area=700,\n",
        "    ar_min=1.05,\n",
        "    ar_max=6.5,\n",
        "    device=None,\n",
        "):\n",
        "    maes, ems = [], []\n",
        "    for th in thresholds:\n",
        "        mae, em, n = evaluate_image_folder_metrics(\n",
        "            folder_path,\n",
        "            threshold=th,\n",
        "            nms_iou=fixed_nms_iou,\n",
        "            min_box_area=fixed_min_box_area,\n",
        "            ar_min=ar_min,\n",
        "            ar_max=ar_max,\n",
        "            device=device,\n",
        "        )\n",
        "        maes.append(mae)\n",
        "        ems.append(em)\n",
        "        print(f\"threshold={th:.2f} | MAE={mae:.3f} | ExactMatch={em*100:.1f}% (N={n})\")\n",
        "\n",
        "    # Plot MAE\n",
        "    plt.figure()\n",
        "    plt.plot(list(thresholds), maes, marker=\"o\")\n",
        "    plt.xlabel(\"threshold\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.title(\"MAE vs threshold\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Exact Match\n",
        "    plt.figure()\n",
        "    plt.plot(list(thresholds), [e*100 for e in ems], marker=\"o\")\n",
        "    plt.xlabel(\"threshold\")\n",
        "    plt.ylabel(\"Exact Match Rate (%)\")\n",
        "    plt.title(\"Exact Match Rate vs threshold\")\n",
        "    plt.show()\n",
        "\n",
        "    best_idx = int(np.argmin(maes))\n",
        "    print(f\"Best (by lowest MAE): threshold={thresholds[best_idx]:.2f} | MAE={maes[best_idx]:.3f} | ExactMatch={ems[best_idx]*100:.1f}%\")\n",
        "    return {\"thresholds\": list(thresholds), \"mae\": maes, \"exact_match\": ems}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-Uq4KHRObmR"
      },
      "source": [
        "**Sweep + Plot: nms_iou**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cMAqnkHOkMs"
      },
      "outputs": [],
      "source": [
        "def sweep_and_plot_nms_iou(\n",
        "    folder_path: str,\n",
        "    nms_ious=(0.3, 0.4, 0.5, 0.6, 0.7),\n",
        "    fixed_threshold=0.4,\n",
        "    fixed_min_box_area=700,\n",
        "    ar_min=1.05,\n",
        "    ar_max=6.5,\n",
        "    device=None,\n",
        "):\n",
        "    maes, ems = [], []\n",
        "    for iou in nms_ious:\n",
        "        mae, em, n = evaluate_image_folder_metrics(\n",
        "            folder_path,\n",
        "            threshold=fixed_threshold,\n",
        "            nms_iou=iou,\n",
        "            min_box_area=fixed_min_box_area,\n",
        "            ar_min=ar_min,\n",
        "            ar_max=ar_max,\n",
        "            device=device,\n",
        "        )\n",
        "        maes.append(mae)\n",
        "        ems.append(em)\n",
        "        print(f\"nms_iou={iou:.2f} | MAE={mae:.3f} | ExactMatch={em*100:.1f}% (N={n})\")\n",
        "\n",
        "    # Plot MAE\n",
        "    plt.figure()\n",
        "    plt.plot(list(nms_ious), maes, marker=\"o\")\n",
        "    plt.xlabel(\"nms_iou\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.title(\"MAE vs nms_iou\")\n",
        "    plt.show()\n",
        "\n",
        "    # Plot Exact Match\n",
        "    plt.figure()\n",
        "    plt.plot(list(nms_ious), [e*100 for e in ems], marker=\"o\")\n",
        "    plt.xlabel(\"nms_iou\")\n",
        "    plt.ylabel(\"Exact Match Rate (%)\")\n",
        "    plt.title(\"Exact Match Rate vs nms_iou\")\n",
        "    plt.show()\n",
        "\n",
        "    best_idx = int(np.argmin(maes))\n",
        "    print(f\"Best (by lowest MAE): nms_iou={nms_ious[best_idx]:.2f} | MAE={maes[best_idx]:.3f} | ExactMatch={ems[best_idx]*100:.1f}%\")\n",
        "    return {\"nms_ious\": list(nms_ious), \"mae\": maes, \"exact_match\": ems}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q91Xt3whOnP2"
      },
      "source": [
        "**Sweep + Plot: Min Box Area**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5KcJopGO6X1"
      },
      "outputs": [],
      "source": [
        "def sweep_and_plot_min_box_area(\n",
        "    folder_path: str,\n",
        "    min_areas=(0, 200, 400, 700, 1000, 1500),\n",
        "    fixed_threshold=0.4,\n",
        "    fixed_nms_iou=0.60,\n",
        "    ar_min=1.05,\n",
        "    ar_max=6.5,\n",
        "    device=None,\n",
        "):\n",
        "    maes, ems = [], []\n",
        "    for a in min_areas:\n",
        "        mae, em, n = evaluate_image_folder_metrics(\n",
        "            folder_path,\n",
        "            threshold=fixed_threshold,\n",
        "            nms_iou=fixed_nms_iou,\n",
        "            min_box_area=int(a),\n",
        "            ar_min=ar_min,\n",
        "            ar_max=ar_max,\n",
        "            device=device,\n",
        "        )\n",
        "        maes.append(mae)\n",
        "        ems.append(em)\n",
        "        print(f\"min_box_area={int(a)} | MAE={mae:.3f} | ExactMatch={em*100:.1f}% (N={n})\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(list(min_areas), maes, marker=\"o\")\n",
        "    plt.xlabel(\"min_box_area (px^2)\")\n",
        "    plt.ylabel(\"MAE\")\n",
        "    plt.title(\"MAE vs min_box_area\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(list(min_areas), [e*100 for e in ems], marker=\"o\")\n",
        "    plt.xlabel(\"min_box_area (px^2)\")\n",
        "    plt.ylabel(\"Exact Match Rate (%)\")\n",
        "    plt.title(\"Exact Match Rate vs min_box_area\")\n",
        "    plt.show()\n",
        "\n",
        "    best_idx = int(np.argmin(maes))\n",
        "    print(f\"Best (by lowest MAE): min_box_area={min_areas[best_idx]} | MAE={maes[best_idx]:.3f} | ExactMatch={ems[best_idx]*100:.1f}%\")\n",
        "    return {\"min_areas\": list(min_areas), \"mae\": maes, \"exact_match\": ems}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSfihOICKf7t"
      },
      "source": [
        "# Testing: Static Pictures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2YKIM0c9OKj"
      },
      "source": [
        "**Test Cells: Intial first Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "o_QdxHrt9L_6"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open(r\"/content/05_8.jpg\").convert(\"RGB\")\n",
        "\n",
        "out = detect_people(img, threshold=0.4, min_box_area=300, nms_iou=0.6)\n",
        "print(\"People:\", out[\"count\"])\n",
        "# out.keys(), out[\"boxes\"][:2], out[\"scores\"][:2]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pltD3rHo9mwp"
      },
      "outputs": [],
      "source": [
        "annotated = visualize_people(img, out)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(annotated)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"People count: {out['count']} | {out['debug']}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asf5USQyVF8f"
      },
      "source": [
        "**Helpers for Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnAqBX6nS3zQ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# ---------- Helpers: parsing + evaluation ----------\n",
        "\n",
        "def _list_images(folder_path, extensions=(\".jpg\",\".jpeg\",\".png\",\".bmp\",\".webp\")):\n",
        "    folder = Path(folder_path)\n",
        "    paths = sorted([p for p in folder.iterdir() if p.suffix.lower() in extensions])\n",
        "    if len(paths) == 0:\n",
        "        raise ValueError(f\"No images found in: {folder_path}\")\n",
        "    return paths\n",
        "\n",
        "def _parse_gt_from_name(path: Path):\n",
        "    \"\"\"\n",
        "    Expected: <id>_<gt>.<ext>, e.g. 0001_6.jpg\n",
        "    Returns gt (int) or None if filename doesn't match.\n",
        "    \"\"\"\n",
        "    m = re.match(r\"^(?P<id>.+)_(?P<gt>\\d+)$\", path.stem)\n",
        "    if not m:\n",
        "        return None\n",
        "    return int(m.group(\"gt\"))\n",
        "\n",
        "def evaluate_folder_detailed(\n",
        "    folder_path: str,\n",
        "    threshold: float,\n",
        "    nms_iou: float,\n",
        "    min_box_area: int,\n",
        "    ar_min: float = 1.05,\n",
        "    ar_max: float = 6.5,\n",
        "    device=None,\n",
        "    verbose=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      summary dict: MAE, ExactMatch, N, params\n",
        "      df: per-image results with abs_error\n",
        "    \"\"\"\n",
        "    paths = _list_images(folder_path)\n",
        "    rows = []\n",
        "    skipped = 0\n",
        "\n",
        "    for p in paths:\n",
        "        gt = _parse_gt_from_name(p)\n",
        "        if gt is None:\n",
        "            skipped += 1\n",
        "            continue\n",
        "\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        out = detect_people(\n",
        "            img,\n",
        "            threshold=threshold,\n",
        "            nms_iou=nms_iou,\n",
        "            min_box_area=min_box_area,\n",
        "            ar_min=ar_min,\n",
        "            ar_max=ar_max,\n",
        "            device=device,\n",
        "        )\n",
        "        pred = int(out[\"count\"])\n",
        "        abs_err = abs(pred - gt)\n",
        "\n",
        "        rows.append({\n",
        "            \"file\": p.name,\n",
        "            \"path\": str(p),\n",
        "            \"gt\": gt,\n",
        "            \"pred\": pred,\n",
        "            \"abs_error\": abs_err,\n",
        "        })\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"{p.name}: GT={gt}, Pred={pred}, |err|={abs_err}\")\n",
        "\n",
        "    if len(rows) == 0:\n",
        "        raise ValueError(\"No valid images matched '<id>_<gt>.<ext>' naming format.\")\n",
        "\n",
        "    df = pd.DataFrame(rows).sort_values([\"abs_error\", \"file\"], ascending=[False, True]).reset_index(drop=True)\n",
        "    mae = float(df[\"abs_error\"].mean())\n",
        "    exact = float((df[\"abs_error\"] == 0).mean())\n",
        "\n",
        "    summary = {\n",
        "        \"N_total_files\": len(paths),\n",
        "        \"N_evaluated\": int(len(df)),\n",
        "        \"N_skipped_bad_name\": int(skipped),\n",
        "        \"MAE\": mae,\n",
        "        \"ExactMatch\": exact,\n",
        "        \"params\": {\n",
        "            \"threshold\": float(threshold),\n",
        "            \"nms_iou\": float(nms_iou),\n",
        "            \"min_box_area\": int(min_box_area),\n",
        "            \"ar_min\": float(ar_min),\n",
        "            \"ar_max\": float(ar_max),\n",
        "        }\n",
        "    }\n",
        "    return summary, df\n",
        "\n",
        "# ---------- Plotting helpers ----------\n",
        "\n",
        "import os\n",
        "\n",
        "def _plot_curve(x, y, xlabel, ylabel, title, save_path=None, dpi=200):\n",
        "    plt.figure()\n",
        "    plt.plot(list(x), list(y), marker=\"o\")\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    if save_path is not None:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(save_path, dpi=dpi, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def _pick_best_worst(results_df, metric=\"MAE\"):\n",
        "    \"\"\"\n",
        "    results_df has columns: param_value, MAE, ExactMatch\n",
        "    Returns best_row, worst_row by min/max metric.\n",
        "    \"\"\"\n",
        "    best = results_df.loc[results_df[metric].idxmin()].to_dict()\n",
        "    worst = results_df.loc[results_df[metric].idxmax()].to_dict()\n",
        "    return best, worst\n",
        "\n",
        "# ---------- Sweeps (sequential) ----------\n",
        "# We do sequential sweeps because that's fast and interpretable:\n",
        "# 1) sweep threshold with fixed nms_iou/min_box_area\n",
        "# 2) sweep nms_iou using best threshold (fixed min_box_area)\n",
        "# 3) sweep min_box_area using best threshold + best nms_iou\n",
        "\n",
        "def run_all_sweeps(\n",
        "    folder_path: str,\n",
        "    thresholds=(0.2, 0.3, 0.4, 0.5, 0.6),\n",
        "    nms_ious=(0.3, 0.4, 0.5, 0.6, 0.7),\n",
        "    min_areas=(0, 200, 400, 700, 1000, 1500),\n",
        "    base_threshold=0.4,\n",
        "    base_nms_iou=0.6,\n",
        "    base_min_box_area=700,\n",
        "    ar_min=1.05,\n",
        "    ar_max=6.5,\n",
        "    device=None,\n",
        "    plots_dir=\"/content/eval_plots\",\n",
        "):\n",
        "    os.makedirs(plots_dir, exist_ok=True)\n",
        "\n",
        "    # ---- 1) Threshold sweep ----\n",
        "    th_rows = []\n",
        "    for th in thresholds:\n",
        "        s, _ = evaluate_folder_detailed(\n",
        "            folder_path, threshold=th, nms_iou=base_nms_iou, min_box_area=base_min_box_area,\n",
        "            ar_min=ar_min, ar_max=ar_max, device=device, verbose=False\n",
        "        )\n",
        "        th_rows.append({\"param\": \"threshold\", \"value\": th, \"MAE\": s[\"MAE\"], \"ExactMatch\": s[\"ExactMatch\"]})\n",
        "        print(f\"[TH] th={th:.2f} | MAE={s['MAE']:.3f} | Exact={s['ExactMatch']*100:.1f}%\")\n",
        "\n",
        "    df_th = pd.DataFrame(th_rows)\n",
        "    _plot_curve(\n",
        "        df_th[\"value\"], df_th[\"MAE\"],\n",
        "        \"threshold\", \"MAE\", \"MAE vs threshold\",\n",
        "        save_path=os.path.join(plots_dir, \"MAE_vs_threshold.png\")\n",
        "    )\n",
        "    _plot_curve(\n",
        "        df_th[\"value\"], df_th[\"ExactMatch\"]*100,\n",
        "        \"threshold\", \"Exact Match Rate (%)\", \"Exact Match vs threshold\",\n",
        "        save_path=os.path.join(plots_dir, \"ExactMatch_vs_threshold.png\")\n",
        "    )\n",
        "\n",
        "    best_th, worst_th = _pick_best_worst(df_th, metric=\"MAE\")\n",
        "    best_threshold = float(best_th[\"value\"])\n",
        "    worst_threshold = float(worst_th[\"value\"])\n",
        "\n",
        "    print(\"\\nBest threshold (by MAE):\", best_th)\n",
        "    print(\"Worst threshold (by MAE):\", worst_th)\n",
        "\n",
        "    # ---- 2) NMS sweep (use best threshold) ----\n",
        "    iou_rows = []\n",
        "    for iou in nms_ious:\n",
        "        s, _ = evaluate_folder_detailed(\n",
        "            folder_path, threshold=best_threshold, nms_iou=iou, min_box_area=base_min_box_area,\n",
        "            ar_min=ar_min, ar_max=ar_max, device=device, verbose=False\n",
        "        )\n",
        "        iou_rows.append({\"param\": \"nms_iou\", \"value\": iou, \"MAE\": s[\"MAE\"], \"ExactMatch\": s[\"ExactMatch\"]})\n",
        "        print(f\"[NMS] iou={iou:.2f} | MAE={s['MAE']:.3f} | Exact={s['ExactMatch']*100:.1f}%\")\n",
        "\n",
        "    df_iou = pd.DataFrame(iou_rows)\n",
        "    _plot_curve(\n",
        "        df_iou[\"value\"], df_iou[\"MAE\"],\n",
        "        \"nms_iou\", \"MAE\", f\"MAE vs nms_iou (th={best_threshold:.2f})\",\n",
        "        save_path=os.path.join(plots_dir, f\"MAE_vs_nms_iou_th{best_threshold:.2f}.png\")\n",
        "    )\n",
        "    _plot_curve(\n",
        "        df_iou[\"value\"], df_iou[\"ExactMatch\"]*100,\n",
        "        \"nms_iou\", \"Exact Match Rate (%)\", f\"Exact Match vs nms_iou (th={best_threshold:.2f})\",\n",
        "        save_path=os.path.join(plots_dir, f\"ExactMatch_vs_nms_iou_th{best_threshold:.2f}.png\")\n",
        "    )\n",
        "\n",
        "    best_iou, worst_iou = _pick_best_worst(df_iou, metric=\"MAE\")\n",
        "    best_nms_iou = float(best_iou[\"value\"])\n",
        "    worst_nms_iou = float(worst_iou[\"value\"])\n",
        "\n",
        "    print(\"\\nBest nms_iou (by MAE):\", best_iou)\n",
        "    print(\"Worst nms_iou (by MAE):\", worst_iou)\n",
        "\n",
        "    # ---- 3) min_box_area sweep (use best threshold + best nms) ----\n",
        "    area_rows = []\n",
        "    for a in min_areas:\n",
        "        s, _ = evaluate_folder_detailed(\n",
        "            folder_path, threshold=best_threshold, nms_iou=best_nms_iou, min_box_area=int(a),\n",
        "            ar_min=ar_min, ar_max=ar_max, device=device, verbose=False\n",
        "        )\n",
        "        area_rows.append({\"param\": \"min_box_area\", \"value\": int(a), \"MAE\": s[\"MAE\"], \"ExactMatch\": s[\"ExactMatch\"]})\n",
        "        print(f\"[AREA] area={int(a)} | MAE={s['MAE']:.3f} | Exact={s['ExactMatch']*100:.1f}%\")\n",
        "\n",
        "    df_area = pd.DataFrame(area_rows)\n",
        "    _plot_curve(\n",
        "        df_area[\"value\"], df_area[\"MAE\"],\n",
        "        \"min_box_area (px^2)\", \"MAE\",\n",
        "        f\"MAE vs min_box_area (th={best_threshold:.2f}, nms={best_nms_iou:.2f})\",\n",
        "        save_path=os.path.join(plots_dir, f\"MAE_vs_min_box_area_th{best_threshold:.2f}_nms{best_nms_iou:.2f}.png\")\n",
        "    )\n",
        "    _plot_curve(\n",
        "        df_area[\"value\"], df_area[\"ExactMatch\"]*100,\n",
        "        \"min_box_area (px^2)\", \"Exact Match Rate (%)\",\n",
        "        f\"Exact Match vs min_box_area (th={best_threshold:.2f}, nms={best_nms_iou:.2f})\",\n",
        "        save_path=os.path.join(plots_dir, f\"ExactMatch_vs_min_box_area_th{best_threshold:.2f}_nms{best_nms_iou:.2f}.png\")\n",
        "    )\n",
        "\n",
        "    best_area, worst_area = _pick_best_worst(df_area, metric=\"MAE\")\n",
        "    best_min_area = int(best_area[\"value\"])\n",
        "    worst_min_area = int(worst_area[\"value\"])\n",
        "\n",
        "    print(\"\\nBest min_box_area (by MAE):\", best_area)\n",
        "    print(\"Worst min_box_area (by MAE):\", worst_area)\n",
        "\n",
        "    best_params = {\"threshold\": best_threshold, \"nms_iou\": best_nms_iou, \"min_box_area\": best_min_area, \"ar_min\": ar_min, \"ar_max\": ar_max}\n",
        "    worst_params = {\"threshold\": float(worst_threshold), \"nms_iou\": float(worst_nms_iou), \"min_box_area\": int(worst_min_area), \"ar_min\": ar_min, \"ar_max\": ar_max}\n",
        "\n",
        "    print(f\"\\nSaved plots to: {plots_dir}\")\n",
        "\n",
        "    return {\n",
        "        \"df_threshold\": df_th,\n",
        "        \"df_nms\": df_iou,\n",
        "        \"df_area\": df_area,\n",
        "        \"best_params\": best_params,\n",
        "        \"worst_params\": worst_params,\n",
        "        \"plots_dir\": plots_dir\n",
        "    }\n",
        "\n",
        "# ---------- Visualization artifacts ----------\n",
        "def save_comparison_images(\n",
        "    worst_df: pd.DataFrame,\n",
        "    folder_path: str,\n",
        "    worst_params: dict,\n",
        "    best_params: dict,\n",
        "    device=None,\n",
        "    out_dir=\"/content/eval_outputs\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Finds the worst-recognition image under worst_params (max abs_error from worst_df),\n",
        "    then saves two annotated images: worst params and best params.\n",
        "    \"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Pick worst example (highest abs error)\n",
        "    worst_row = worst_df.iloc[0].to_dict()\n",
        "    img_path = worst_row[\"path\"]\n",
        "    filename = worst_row[\"file\"]\n",
        "    gt = int(worst_row[\"gt\"])\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "    # Worst params detection + viz\n",
        "    out_w = detect_people(img, device=device, **worst_params)\n",
        "    vis_w = visualize_people(img, out_w)\n",
        "    pred_w = int(out_w[\"count\"])\n",
        "    out_w_path = os.path.join(out_dir, f\"WORSTPARAMS_{Path(filename).stem}_GT{gt}_P{pred_w}.png\")\n",
        "    vis_w.save(out_w_path)\n",
        "\n",
        "    # Best params detection + viz\n",
        "    out_b = detect_people(img, device=device, **best_params)\n",
        "    vis_b = visualize_people(img, out_b)\n",
        "    pred_b = int(out_b[\"count\"])\n",
        "    out_b_path = os.path.join(out_dir, f\"BESTPARAMS_{Path(filename).stem}_GT{gt}_P{pred_b}.png\")\n",
        "    vis_b.save(out_b_path)\n",
        "\n",
        "    print(\"Worst-recognition image:\", filename, \"| GT=\", gt)\n",
        "    print(\"Saved:\")\n",
        "    print(\" -\", out_w_path)\n",
        "    print(\" -\", out_b_path)\n",
        "\n",
        "    return {\n",
        "        \"worst_image_file\": filename,\n",
        "        \"worst_image_path\": img_path,\n",
        "        \"gt\": gt,\n",
        "        \"pred_worst\": pred_w,\n",
        "        \"pred_best\": pred_b,\n",
        "        \"saved_worst_viz\": out_w_path,\n",
        "        \"saved_best_viz\": out_b_path,\n",
        "        \"debug_worst\": out_w[\"debug\"],\n",
        "        \"debug_best\": out_b[\"debug\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPYkXao-V_lf"
      },
      "source": [
        "**Usage on Picture Folder (20)**\n",
        "\n",
        "* Sweep threshold, NMS IoU, min_box_area (with graphs)\n",
        "\n",
        "* Find and save best and worst parameter sets (by MAE)\n",
        "\n",
        "* For best + worst: print overall MAE + Exact Match on the whole folder\n",
        "\n",
        "* Find the worst-recognition image under the worst parameters (max abs error)\n",
        "Produce and save two annotated images of that same file:\n",
        "  1. with worst parameters\n",
        "  2. with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hnblj73fV_Wn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "folder_path = \"/content/20_pictures\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "plots_dir = \"/content/eval_plots\"\n",
        "outputs_dir = \"/content/eval_outputs\"\n",
        "tables_dir = \"/content/eval_tables\"\n",
        "\n",
        "os.makedirs(plots_dir, exist_ok=True)\n",
        "os.makedirs(outputs_dir, exist_ok=True)\n",
        "os.makedirs(tables_dir, exist_ok=True)\n",
        "\n",
        "print(\"Folder:\", folder_path)\n",
        "print(\"Device:\", device)\n",
        "print(\"Plots dir:\", plots_dir)\n",
        "print(\"Outputs dir:\", outputs_dir)\n",
        "print(\"Tables dir:\", tables_dir)\n",
        "\n",
        "# =========================\n",
        "# 1) Sweeps (saves plots automatically)\n",
        "# =========================\n",
        "sweep_res = run_all_sweeps(\n",
        "    folder_path=folder_path,\n",
        "    thresholds=(0.2, 0.3, 0.4, 0.5, 0.6),\n",
        "    nms_ious=(0.3, 0.4, 0.5, 0.6, 0.7),\n",
        "    min_areas=(0, 200, 400, 700, 1000, 1500),\n",
        "    base_threshold=0.4,\n",
        "    base_nms_iou=0.60,\n",
        "    base_min_box_area=700,\n",
        "    device=device,\n",
        "    plots_dir=plots_dir,  # <-- IMPORTANT so graphs are saved\n",
        ")\n",
        "\n",
        "best_params = sweep_res[\"best_params\"]\n",
        "worst_params = sweep_res[\"worst_params\"]\n",
        "\n",
        "print(\"\\n=== BEST PARAMS (sequential best-by-MAE) ===\")\n",
        "print(best_params)\n",
        "\n",
        "print(\"\\n=== WORST PARAMS (sequential worst-by-MAE) ===\")\n",
        "print(worst_params)\n",
        "\n",
        "# =========================\n",
        "# 2) Evaluate best/worst on whole folder + save per-image tables\n",
        "# =========================\n",
        "best_summary, best_df = evaluate_folder_detailed(folder_path, device=device, **best_params)\n",
        "worst_summary, worst_df = evaluate_folder_detailed(folder_path, device=device, **worst_params)\n",
        "\n",
        "best_csv = os.path.join(tables_dir, \"per_image_results_BEST.csv\")\n",
        "worst_csv = os.path.join(tables_dir, \"per_image_results_WORST.csv\")\n",
        "best_df.to_csv(best_csv, index=False)\n",
        "worst_df.to_csv(worst_csv, index=False)\n",
        "\n",
        "print(\"\\n=== Overall performance on whole folder ===\")\n",
        "print(f\"BEST  -> MAE={best_summary['MAE']:.3f} | ExactMatch={best_summary['ExactMatch']*100:.1f}% | N={best_summary['N_evaluated']}\")\n",
        "print(f\"WORST -> MAE={worst_summary['MAE']:.3f} | ExactMatch={worst_summary['ExactMatch']*100:.1f}% | N={worst_summary['N_evaluated']}\")\n",
        "print(\"\\nSaved per-image CSVs:\")\n",
        "print(\" -\", best_csv)\n",
        "print(\" -\", worst_csv)\n",
        "\n",
        "# =========================\n",
        "# 3) Visualize the worst-recognition image (according to WORST params)\n",
        "# =========================\n",
        "artifact = save_comparison_images(\n",
        "    worst_df=worst_df,\n",
        "    folder_path=folder_path,\n",
        "    worst_params=worst_params,\n",
        "    best_params=best_params,\n",
        "    device=device,\n",
        "    out_dir=outputs_dir,\n",
        ")\n",
        "\n",
        "print(\"\\nSaved visualizations:\")\n",
        "print(\" -\", artifact[\"saved_worst_viz\"])\n",
        "print(\" -\", artifact[\"saved_best_viz\"])\n",
        "\n",
        "# Show inline\n",
        "display(Image.open(artifact[\"saved_worst_viz\"]))\n",
        "display(Image.open(artifact[\"saved_best_viz\"]))\n",
        "\n",
        "# =========================\n",
        "# 4) Quick directory listing (optional)\n",
        "# =========================\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"Plots:\", os.listdir(plots_dir))\n",
        "print(\"Outputs:\", os.listdir(outputs_dir))\n",
        "print(\"Tables:\", os.listdir(tables_dir))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3SpImYYGyY2"
      },
      "source": [
        "# Implementation: Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgmTsE7e-3De"
      },
      "outputs": [],
      "source": [
        "!pip -q install opencv-python\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0zYdq7yG-xU"
      },
      "outputs": [],
      "source": [
        "def bgr_to_pil(frame_bgr):\n",
        "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
        "    return Image.fromarray(frame_rgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3d-hUeLHC3y"
      },
      "outputs": [],
      "source": [
        "def run_detection_on_video(\n",
        "    video_path,\n",
        "    every_n_frames=3,\n",
        "    threshold=0.4,\n",
        "    min_box_area=300,\n",
        "    nms_iou = 0.5,\n",
        "    device=None,\n",
        "    max_frames=None,\n",
        "):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    frame_idx = 0\n",
        "    detections_per_frame = []  # list of dicts: {frame_idx, boxes, scores}\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        if max_frames is not None and frame_idx >= max_frames:\n",
        "            break\n",
        "\n",
        "        if frame_idx % every_n_frames == 0:\n",
        "            pil_img = bgr_to_pil(frame)\n",
        "            out = detect_people(\n",
        "                pil_img,\n",
        "                threshold = threshold,\n",
        "                min_box_area = min_box_area,\n",
        "                nms_iou = nms_iou,\n",
        "                device = device\n",
        "            )\n",
        "            detections_per_frame.append({\n",
        "                \"frame_idx\": frame_idx,\n",
        "                \"boxes\": out[\"boxes\"].numpy(),   # (N,4)\n",
        "                \"scores\": out[\"scores\"].numpy()  # (N,)\n",
        "            })\n",
        "\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    return detections_per_frame, fps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KB6aerLLb2g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def iou_xyxy(a, b):\n",
        "    # a,b: [x1,y1,x2,y2]\n",
        "    x1 = max(a[0], b[0])\n",
        "    y1 = max(a[1], b[1])\n",
        "    x2 = min(a[2], b[2])\n",
        "    y2 = min(a[3], b[3])\n",
        "\n",
        "    inter_w = max(0.0, x2 - x1)\n",
        "    inter_h = max(0.0, y2 - y1)\n",
        "    inter = inter_w * inter_h\n",
        "\n",
        "    area_a = max(0.0, a[2] - a[0]) * max(0.0, a[3] - a[1])\n",
        "    area_b = max(0.0, b[2] - b[0]) * max(0.0, b[3] - b[1])\n",
        "    union = area_a + area_b - inter + 1e-9\n",
        "    return inter / union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_quAHBMLgnr"
      },
      "outputs": [],
      "source": [
        "def greedy_match_iou(tracks_boxes, det_boxes, iou_thresh):\n",
        "    \"\"\"\n",
        "    Returns list of (track_idx, det_idx) matches using greedy IoU.\n",
        "    \"\"\"\n",
        "    if len(tracks_boxes) == 0 or len(det_boxes) == 0:\n",
        "        return []\n",
        "\n",
        "    # IoU matrix [T, D]\n",
        "    ious = np.zeros((len(tracks_boxes), len(det_boxes)), dtype=np.float32)\n",
        "    for t in range(len(tracks_boxes)):\n",
        "        for d in range(len(det_boxes)):\n",
        "            ious[t, d] = iou_xyxy(tracks_boxes[t], det_boxes[d])\n",
        "\n",
        "    matches = []\n",
        "    used_t = set()\n",
        "    used_d = set()\n",
        "\n",
        "    # Flatten sorted by IoU descending\n",
        "    flat = [(t, d, ious[t, d]) for t in range(ious.shape[0]) for d in range(ious.shape[1])]\n",
        "    flat.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    for t, d, v in flat:\n",
        "        if v < iou_thresh:\n",
        "            break\n",
        "        if t in used_t or d in used_d:\n",
        "            continue\n",
        "        used_t.add(t)\n",
        "        used_d.add(d)\n",
        "        matches.append((t, d))\n",
        "\n",
        "    return matches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIrMLzTKLh4L"
      },
      "outputs": [],
      "source": [
        "class Track:\n",
        "    def __init__(self, track_id, box, score, frame_idx):\n",
        "        self.id = track_id\n",
        "        self.box = box.astype(np.float32)\n",
        "        self.score = float(score)\n",
        "        self.last_frame = int(frame_idx)\n",
        "\n",
        "        self.hits = 1         # number of times matched\n",
        "        self.age = 0          # frames since last match (in sampled frames)\n",
        "\n",
        "    def update(self, box, score, frame_idx, smooth=0.7):\n",
        "        # Optional smoothing to reduce jitter\n",
        "        self.box = smooth * self.box + (1 - smooth) * box.astype(np.float32)\n",
        "        self.score = float(score)\n",
        "        self.last_frame = int(frame_idx)\n",
        "        self.hits += 1\n",
        "        self.age = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyHzdd7rLmsV"
      },
      "outputs": [],
      "source": [
        "def track_unique_people(\n",
        "    detections_per_frame,\n",
        "    iou_match_thresh=0.35,\n",
        "    max_age=3,\n",
        "    min_hits=2,\n",
        "    smooth=0.7,\n",
        "):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      detections_per_frame: list of dicts from Step 1:\n",
        "        {\"frame_idx\": int, \"boxes\": (N,4) np array, \"scores\": (N,) np array}\n",
        "\n",
        "    Returns:\n",
        "      total_unique_confirmed: int\n",
        "      tracks_history: list of summary per frame (optional debug)\n",
        "    \"\"\"\n",
        "    tracks = []\n",
        "    next_id = 1\n",
        "    confirmed_ids = set()\n",
        "    history = []\n",
        "\n",
        "    for item in detections_per_frame:\n",
        "        frame_idx = item[\"frame_idx\"]\n",
        "        det_boxes = item[\"boxes\"]\n",
        "        det_scores = item[\"scores\"]\n",
        "\n",
        "        # Age all tracks (they might get matched and reset to 0)\n",
        "        for tr in tracks:\n",
        "            tr.age += 1\n",
        "\n",
        "        tracks_boxes = [tr.box for tr in tracks]\n",
        "        matches = greedy_match_iou(tracks_boxes, det_boxes, iou_match_thresh)\n",
        "\n",
        "        matched_tracks = set()\n",
        "        matched_dets = set()\n",
        "\n",
        "        # Update matched tracks\n",
        "        for t_idx, d_idx in matches:\n",
        "            tracks[t_idx].update(det_boxes[d_idx], det_scores[d_idx], frame_idx, smooth=smooth)\n",
        "            matched_tracks.add(t_idx)\n",
        "            matched_dets.add(d_idx)\n",
        "\n",
        "            if tracks[t_idx].hits >= min_hits:\n",
        "                confirmed_ids.add(tracks[t_idx].id)\n",
        "\n",
        "        # Create new tracks for unmatched detections\n",
        "        for d_idx in range(len(det_boxes)):\n",
        "            if d_idx in matched_dets:\n",
        "                continue\n",
        "            tr = Track(next_id, det_boxes[d_idx], det_scores[d_idx], frame_idx)\n",
        "            tracks.append(tr)\n",
        "            next_id += 1\n",
        "\n",
        "        # Remove dead tracks\n",
        "        tracks = [tr for tr in tracks if tr.age <= max_age]\n",
        "\n",
        "        # Debug snapshot (optional)\n",
        "        history.append({\n",
        "            \"frame_idx\": frame_idx,\n",
        "            \"num_dets\": int(len(det_boxes)),\n",
        "            \"num_tracks_alive\": int(len(tracks)),\n",
        "            \"num_confirmed_total\": int(len(confirmed_ids)),\n",
        "        })\n",
        "\n",
        "    return len(confirmed_ids), history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4WvmwLXOmJ-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def draw_tracks_on_frame(frame_bgr, tracks, color=(0, 255, 0)):\n",
        "    \"\"\"\n",
        "    frame_bgr: OpenCV image\n",
        "    tracks: list of Track objects (alive tracks)\n",
        "    \"\"\"\n",
        "    out = frame_bgr.copy()\n",
        "    for tr in tracks:\n",
        "        x1, y1, x2, y2 = tr.box\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        cv2.rectangle(out, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "        label = f\"ID {tr.id} | hits {tr.hits}\"\n",
        "        cv2.putText(out, label, (x1, max(0, y1 - 8)),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGfPfRWUOoiw"
      },
      "outputs": [],
      "source": [
        "def track_unique_people_with_snapshots(\n",
        "    detections_per_frame,\n",
        "    iou_match_thresh=0.35,\n",
        "    max_age=3,\n",
        "    min_hits=2,\n",
        "    smooth=0.7,\n",
        "):\n",
        "    tracks = []\n",
        "    next_id = 1\n",
        "    confirmed_ids = set()\n",
        "\n",
        "    # frame_idx -> list of (id, box, hits) for drawing\n",
        "    snapshots = {}\n",
        "\n",
        "    for item in detections_per_frame:\n",
        "        frame_idx = item[\"frame_idx\"]\n",
        "        det_boxes = item[\"boxes\"]\n",
        "        det_scores = item[\"scores\"]\n",
        "\n",
        "        for tr in tracks:\n",
        "            tr.age += 1\n",
        "\n",
        "        tracks_boxes = [tr.box for tr in tracks]\n",
        "        matches = greedy_match_iou(tracks_boxes, det_boxes, iou_match_thresh)\n",
        "\n",
        "        matched_tracks = set()\n",
        "        matched_dets = set()\n",
        "\n",
        "        for t_idx, d_idx in matches:\n",
        "            tracks[t_idx].update(det_boxes[d_idx], det_scores[d_idx], frame_idx, smooth=smooth)\n",
        "            matched_tracks.add(t_idx)\n",
        "            matched_dets.add(d_idx)\n",
        "            if tracks[t_idx].hits >= min_hits:\n",
        "                confirmed_ids.add(tracks[t_idx].id)\n",
        "\n",
        "        for d_idx in range(len(det_boxes)):\n",
        "            if d_idx in matched_dets:\n",
        "                continue\n",
        "            tr = Track(next_id, det_boxes[d_idx], det_scores[d_idx], frame_idx)\n",
        "            tracks.append(tr)\n",
        "            next_id += 1\n",
        "\n",
        "        tracks = [tr for tr in tracks if tr.age <= max_age]\n",
        "\n",
        "        # snapshot for this sampled frame\n",
        "        snapshots[frame_idx] = [\n",
        "            {\"id\": tr.id, \"box\": tr.box.copy(), \"hits\": tr.hits}\n",
        "            for tr in tracks\n",
        "        ]\n",
        "\n",
        "    return len(confirmed_ids), snapshots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWLn7RvIOswr"
      },
      "outputs": [],
      "source": [
        "def render_tracked_video(\n",
        "    input_video_path,\n",
        "    output_video_path,\n",
        "    detections_per_frame,\n",
        "    every_n_frames=3,\n",
        "    iou_match_thresh=0.35,\n",
        "    max_age=3,\n",
        "    min_hits=2,\n",
        "    smooth=0.7,\n",
        "):\n",
        "    # Run tracking once to get snapshots\n",
        "    unique_count, snapshots = track_unique_people_with_snapshots(\n",
        "        detections_per_frame,\n",
        "        iou_match_thresh=iou_match_thresh,\n",
        "        max_age=max_age,\n",
        "        min_hits=min_hits,\n",
        "        smooth=smooth,\n",
        "    )\n",
        "    print(\"Unique people (confirmed):\", unique_count)\n",
        "\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    writer = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))\n",
        "\n",
        "    frame_idx = 0\n",
        "    last_snapshot = []\n",
        "\n",
        "    while True:\n",
        "        ok, frame = cap.read()\n",
        "        if not ok:\n",
        "            break\n",
        "\n",
        "        # Update snapshot only on sampled frames if available\n",
        "        if frame_idx in snapshots:\n",
        "            last_snapshot = snapshots[frame_idx]\n",
        "\n",
        "        # Convert snapshot dicts to Track-like lightweight objects for drawing\n",
        "        class _T: pass\n",
        "        alive = []\n",
        "        for s in last_snapshot:\n",
        "            t = _T()\n",
        "            t.id = s[\"id\"]\n",
        "            t.box = s[\"box\"]\n",
        "            t.hits = s[\"hits\"]\n",
        "            alive.append(t)\n",
        "\n",
        "        annotated = draw_tracks_on_frame(frame, alive)\n",
        "\n",
        "        # Display the dynamic real-time count\n",
        "        cv2.putText(annotated, f\"Unique people (so far): {unique_count}\",\n",
        "                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9,\n",
        "                    (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        writer.write(annotated)\n",
        "        frame_idx += 1\n",
        "\n",
        "    cap.release()\n",
        "    writer.release()\n",
        "    return unique_count, output_video_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfxS3xEdN1Ta"
      },
      "source": [
        "# Testing: Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFO0nkuRHbr9"
      },
      "source": [
        "**Test Cells: Intial first Check**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AOzc2SjHNZp"
      },
      "outputs": [],
      "source": [
        "detections, fps = run_detection_on_video(\n",
        "    \"/content/elevator_film_1.mp4\",\n",
        "    every_n_frames=3,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    max_frames=300  # optional limit while testing\n",
        ")\n",
        "print(\"frames with detections:\", len(detections), \"fps:\", fps)\n",
        "print(\"example:\", detections[0][\"frame_idx\"], detections[0][\"boxes\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9LgrcDQVJDQr"
      },
      "outputs": [],
      "source": [
        "unique_count, hist = track_unique_people(\n",
        "    detections,\n",
        "    iou_match_thresh=0.35,\n",
        "    max_age=3,     # in sampled frames (with every_n_frames=3, this is ~9 real frames)\n",
        "    min_hits=2,\n",
        "    smooth=0.7\n",
        ")\n",
        "\n",
        "print(\"Unique people in video:\", unique_count)\n",
        "print(\"Last history:\", hist[-5:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fr7Pm0DLO3tF"
      },
      "outputs": [],
      "source": [
        "unique_count, out_path = render_tracked_video(\n",
        "    input_video_path=\"/content/elevator_film_1.mp4\",\n",
        "    output_video_path=\"/content/tracked_output_1.mp4\",\n",
        "    detections_per_frame=detections,\n",
        "    every_n_frames=3,\n",
        "    iou_match_thresh=0.35,\n",
        "    max_age=3,\n",
        "    min_hits=2,\n",
        "    smooth=0.7\n",
        ")\n",
        "\n",
        "print(\"Saved:\", out_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Usage on Video Folder (5)**"
      ],
      "metadata": {
        "id": "mEyPKwNeKlI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "VIDEO_EXTS = {\".mp4\", \".mov\", \".avi\", \".mkv\", \".webm\", \".m4v\"}\n",
        "\n",
        "def batch_track_videos(\n",
        "    input_folder: str,\n",
        "    output_folder: str = None,\n",
        "    *,\n",
        "    every_n_frames: int = 3,\n",
        "    threshold: float = 0.4,\n",
        "    min_box_area: int = 300,\n",
        "    nms_iou: float = 0.5,\n",
        "    device: str = None,\n",
        "    max_frames=None,   # keep compatible with older python\n",
        "    # tracker params\n",
        "    iou_match_thresh: float = 0.35,\n",
        "    max_age: int = 3,\n",
        "    min_hits: int = 2,\n",
        "    smooth: float = 0.7,\n",
        "    # options\n",
        "    overwrite: bool = False,\n",
        "    save_csv: bool = True,\n",
        "):\n",
        "    input_folder = Path(input_folder)\n",
        "    if output_folder is None:\n",
        "        output_folder = input_folder / \"tracked_outputs\"\n",
        "    output_folder = Path(output_folder)\n",
        "    output_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if device is None:\n",
        "        device = \"cuda\" if (\"torch\" in globals() and torch.cuda.is_available()) else \"cpu\"\n",
        "\n",
        "    video_paths = sorted([\n",
        "        p for p in input_folder.iterdir()\n",
        "        if p.is_file() and p.suffix.lower() in VIDEO_EXTS\n",
        "    ])\n",
        "\n",
        "    if not video_paths:\n",
        "        raise FileNotFoundError(f\"No videos found in: {input_folder}\")\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for idx, vid_path in enumerate(video_paths, start=1):\n",
        "        stem = vid_path.stem\n",
        "        out_path = output_folder / f\"tracked_{stem}.mp4\"\n",
        "\n",
        "        print(f\"\\n[{idx}/{len(video_paths)}] Processing: {vid_path.name}\")\n",
        "        print(f\"  params: every_n_frames={every_n_frames}, thr={threshold}, area>={min_box_area}, nms_iou={nms_iou}\")\n",
        "\n",
        "        if out_path.exists() and not overwrite:\n",
        "            print(f\"  -> Skipping (already exists): {out_path.name}\")\n",
        "            results.append({\n",
        "                \"video\": vid_path.name,\n",
        "                \"input_path\": str(vid_path),\n",
        "                \"output_path\": str(out_path),\n",
        "                \"fps\": None,\n",
        "                \"frames_with_detections\": None,\n",
        "                \"unique_people\": None,\n",
        "                \"status\": \"skipped_exists\",\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # 1) detection (FIX: pass params through)\n",
        "            detections, fps = run_detection_on_video(\n",
        "                str(vid_path),\n",
        "                every_n_frames=every_n_frames,\n",
        "                threshold=threshold,\n",
        "                min_box_area=min_box_area,\n",
        "                nms_iou=nms_iou,\n",
        "                device=device,\n",
        "                max_frames=max_frames,\n",
        "            )\n",
        "\n",
        "            frames_with_det = len(detections)\n",
        "            print(f\"  detections frames: {frames_with_det}, fps: {fps}\")\n",
        "\n",
        "            if frames_with_det == 0:\n",
        "                print(\"  -> No sampled frames processed or no detections list. Skipping render.\")\n",
        "                results.append({\n",
        "                    \"video\": vid_path.name,\n",
        "                    \"input_path\": str(vid_path),\n",
        "                    \"output_path\": None,\n",
        "                    \"fps\": fps,\n",
        "                    \"frames_with_detections\": 0,\n",
        "                    \"unique_people\": 0,\n",
        "                    \"status\": \"no_detections\",\n",
        "                })\n",
        "                continue\n",
        "\n",
        "            # 2) tracking stats\n",
        "            unique_count, _hist = track_unique_people(\n",
        "                detections,\n",
        "                iou_match_thresh=iou_match_thresh,\n",
        "                max_age=max_age,\n",
        "                min_hits=min_hits,\n",
        "                smooth=smooth\n",
        "            )\n",
        "            print(f\"  unique people (confirmed): {unique_count}\")\n",
        "\n",
        "            # 3) render tracked video\n",
        "            unique_count_render, saved_path = render_tracked_video(\n",
        "                input_video_path=str(vid_path),\n",
        "                output_video_path=str(out_path),\n",
        "                detections_per_frame=detections,\n",
        "                every_n_frames=every_n_frames,\n",
        "                iou_match_thresh=iou_match_thresh,\n",
        "                max_age=max_age,\n",
        "                min_hits=min_hits,\n",
        "                smooth=smooth\n",
        "            )\n",
        "\n",
        "            results.append({\n",
        "                \"video\": vid_path.name,\n",
        "                \"input_path\": str(vid_path),\n",
        "                \"output_path\": str(saved_path),\n",
        "                \"fps\": fps,\n",
        "                \"frames_with_detections\": frames_with_det,\n",
        "                \"unique_people\": int(unique_count_render),\n",
        "                \"status\": \"ok\",\n",
        "            })\n",
        "\n",
        "            print(f\"  saved: {saved_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  !! ERROR on {vid_path.name}: {type(e).__name__}: {e}\")\n",
        "            results.append({\n",
        "                \"video\": vid_path.name,\n",
        "                \"input_path\": str(vid_path),\n",
        "                \"output_path\": None,\n",
        "                \"fps\": None,\n",
        "                \"frames_with_detections\": None,\n",
        "                \"unique_people\": None,\n",
        "                \"status\": f\"error: {type(e).__name__}\",\n",
        "            })\n",
        "\n",
        "    df_summary = pd.DataFrame(results)\n",
        "\n",
        "    if save_csv:\n",
        "        csv_path = output_folder / \"summary.csv\"\n",
        "        df_summary.to_csv(csv_path, index=False)\n",
        "        print(\"\\nSaved summary:\", csv_path)\n",
        "\n",
        "    return df_summary"
      ],
      "metadata": {
        "id": "LwoT5hooGilQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"/content/videos\"\n",
        "summary = batch_track_videos(\n",
        "    input_folder=\"/content/videos\",\n",
        "    output_folder=\"/content/tracked_outputs\",\n",
        "    every_n_frames=3,\n",
        "    threshold=0.4,\n",
        "    min_box_area=300,\n",
        "    nms_iou=0.5,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    max_frames=None,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "display(summary)\n",
        "print(\"\\nSaved outputs in:\", \"/content/tracked_outputs\")"
      ],
      "metadata": {
        "id": "xyGKWsJ9K1XS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}