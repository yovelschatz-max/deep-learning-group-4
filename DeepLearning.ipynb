{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yovelschatz-max/deep-learning-group-4/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkiHf7Jot1T4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f92ef8c",
        "outputId": "1eecf9e5-1eb7-4593-abba-387c75b5499b"
      },
      "source": [
        "import torch\n",
        "import requests\n",
        "\n",
        "from PIL import Image\n",
        "from transformers import RTDetrForObjectDetection, RTDetrImageProcessor\n",
        "\n",
        "# Use the image_path variable from the kernel state to load the image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "image_processor = RTDetrImageProcessor.from_pretrained(\"PekingU/rtdetr_r50vd\")\n",
        "model = RTDetrForObjectDetection.from_pretrained(\"PekingU/rtdetr_r50vd\")\n",
        "\n",
        "inputs = image_processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Post-process the detection results. Adjust the threshold as needed.\n",
        "results = image_processor.post_process_object_detection(outputs, target_sizes=torch.tensor([image.size[::-1]]), threshold=0.9)\n",
        "\n",
        "# Print the detection results\n",
        "print(f\"Detections for {image_path}:\")\n",
        "for result in results:\n",
        "    for score, label_id, box in zip(result[\"scores\"], result[\"labels\"], result[\"boxes\"]):\n",
        "        # Filter for detections that are identified as 'person' (label ID 0 for COCO dataset usually)\n",
        "        # Note: You might need to confirm the exact label ID for 'person' in this specific model's config.\n",
        "        if model.config.id2label[label_id.item()] == 'person': # Assuming 'person' is the target label\n",
        "            score_val, label = score.item(), label_id.item()\n",
        "            box_coords = [round(i, 2) for i in box.tolist()]\n",
        "            print(f\"  {model.config.id2label[label]}: {score_val:.2f} {box_coords}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detections for /content/downloaded_image.jpg:\n"
          ]
        }
      ]
    }
  ]
}